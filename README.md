# ğŸ§  Chat Assistant Demo  
## Session Memory & Ambiguous Query Handling

---

## 1. Má»¥c tiÃªu project

Project nÃ y minh hoáº¡ má»™t **chat assistant backend** cÃ³:

### Session Memory
- LÆ°u há»™i thoáº¡i ngáº¯n háº¡n (<= 10000 tokens)
- Tá»± Ä‘á»™ng **tÃ³m táº¯t (summary)** khi context quÃ¡ dÃ i

### Ambiguous Query Handling
- PhÃ¡t hiá»‡n cÃ¢u há»i mÆ¡ há»“ / nhiá»u lá»—i chÃ­nh táº£
- Rewrite cÃ¢u há»i
- **Há»i láº¡i Ä‘á»ƒ lÃ m rÃµ (clarifying question)**
- KHÃ”NG tráº£ lá»i khi chÆ°a rÃµ Ã½

---

## 2. Cáº¥u trÃºc thÆ° má»¥c & giáº£i thÃ­ch tá»«ng file

```
chat_assistant/
â”œâ”€â”€ main.py
â”œâ”€â”€ demo.py
â”œâ”€â”€ config.py
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ memory/
â”‚   â”œâ”€â”€ session_store.py
â”‚   â””â”€â”€ context_manager.py
â”‚
â”œâ”€â”€ query/
â”‚   â””â”€â”€ pipeline.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ session.json
â”‚   â”œâ”€â”€ test_long.jsonl
â”‚   â””â”€â”€ test_ambiguous.jsonl
â”‚
â””â”€â”€ README.md
```
## 3. Giáº£i thÃ­ch tá»«ng file
```main.py```

- Entry point chÃ­nh
- Cháº¡y chat assistant dáº¡ng CLI
- Gá»i run_query_pipeline
- Káº¿t há»£p:
    - session memory
    - summary
    - ambiguity handling


```demo.py```

- File demo Ä‘á»ƒ test 
- Cháº¡y sáºµn 2 flow:
    - Flow 1: há»™i thoáº¡i dÃ i â†’ sinh summary
    - Flow 2: cÃ¢u mÆ¡ há»“ â†’ há»i láº¡i
- KhÃ´ng cáº§n nháº­p tay


```config.py```

- Chá»©a cÃ¡c cáº¥u hÃ¬nh chung:
    - model name
    - context limit
    - summary threshold

```requirements.txt```

Danh sÃ¡ch cÃ¡c thÆ° viá»‡n cáº§n cÃ i

```memory/session_store.py```

Quáº£n lÃ½ session memory
Session gá»“m:
    - summary
    - recent messages

```memory/context_manager.py```

- Theo dÃµi Ä‘á»™ dÃ i context
- Kiá»ƒm tra khi nÃ o vÆ°á»£t ngÆ°á»¡ng
- Gá»i LLM Ä‘á»ƒ tÃ³m táº¯t há»™i thoáº¡i
- Reset recent messages sau khi summary

```query/pipeline.py```

CÃ i Ä‘áº·t run_query_pipeline

```
User Input
   â†“
Ambiguity Analysis
   â†“
Clarifying Question (náº¿u mÆ¡ há»“)
   â†“
Normal Response (náº¿u rÃµ)
   â†“
Update Session + Summary

```

```data/session.json```

- LÆ°u tráº¡ng thÃ¡i há»™i thoáº¡i hiá»‡n táº¡i
- ÄÆ°á»£c táº¡o vÃ  cáº­p nháº­t tá»± Ä‘á»™ng vÃ  sáº½ xoÃ¡ sau khi summary Ä‘á»ƒ trÃ¡nh trÃ n bá»™ nhá»›

```data/test_long.jsonl```

- Dá»¯ liá»‡u test há»™i thoáº¡i dÃ i
- DÃ¹ng Ä‘á»ƒ:
    - lÃ m Ä‘áº§y context
    - kÃ­ch hoáº¡t summary

```data/test_ambiguous.jsonl```

Dá»¯ liá»‡u test cÃ¢u mÆ¡ há»“

## 4. CÃ i Ä‘áº·t mÃ´i trÆ°á»ng
**4.1 Táº¡o virtual environment** 
```
python -m venv .venv
source .venv/bin/activate
```

**4.2 CÃ i Ä‘áº·t thÆ° viá»‡n**
```
pip install -r requirements.txt
```

## 5. Cáº¥u hÃ¬nh API Key

```
export GOOGLE_API_KEY="YOUR_API_KEY"

```
DÃ¹ng Ä‘á»ƒ set API Key Ä‘á»ƒ summary text, dÃ¹ng báº£n free vá»›i model gemini-flash-2.5

## 6. Cháº¡y DEMO
```
python demo.py
```
**Flow 1 â€” Session Memory + Summary**
Intput:

Má»™t Ä‘oáº¡n há»™i thoáº¡i dÃ i giá»¯a user vÃ  assistant

Output máº«u :
```
==============================
ğŸš€ FLOW 1 â€” SESSION MEMORY DEMO
==============================
[1] Context tokens: 1433
[2] Context tokens: 2518
[3] Context tokens: 2612
[4] Context tokens: 4049
[5] Context tokens: 4126
[6] Context tokens: 5136
[7] Context tokens: 5189
[8] Context tokens: 6114
[9] Context tokens: 6203
[10] Context tokens: 8139
[11] Context tokens: 8180
[12] Context tokens: 9109
[13] Context tokens: 9140
[14] Context tokens: 9895
[15] Context tokens: 9936
[16] Context tokens: 10632
Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.

âš ï¸ Context limit exceeded â†’ summarizing
ğŸ§  Generated summary:
{
  "session_summary": {
    "user_profile": {
      "prefs": [
        "Wants detailed explanations.",
        "Interested in practical applications, especially in data science and real-world examples (e.g., in Vietnam).",
        "Wants clear distinctions between related concepts (e.g., Deep Learning vs Traditional Machine Learning vs Classical Statistics).",
        "Interested in specific architectural comparisons (e.g., Transformer vs RNN/LSTM).",
        "Interested in 'Scaling law', 'post-training techniques' (RLHF, DPO, ORPO, PPO), 'emergent abilities', 'Chain-of-Thought prompting', and 'multimodal learning'."
      ],
      "constraints": [
        "Notes that concepts like Classical Statistics, Traditional ML, and Deep Learning are often confused."
      ]
    },
    "key_facts": [
      "Deep Learning (DL) is a subfield of Machine Learning using multi-layered artificial neural networks to automatically learn hierarchical feature representations from raw data, eliminating manual feature engineering.",
      "Common DL Architectures: CNN, RNN/LSTM/GRU, Transformer, Vision Transformer, Diffusion Models, Graph Neural Networks, Neural ODE, Neural Fields, Mamba.",
      "DL Applications: Computer Vision, Natural Language Processing, Speech Recognition & Synthesis, Recommendation Systems, Time Series Forecasting, Generative AI, Fraud Detection, Biomedicine, Robotics, Materials Science.",
      "Comparison of Classical Statistics, Traditional ML, and Deep Learning across dimensions like Main Goal, Parameters, Feature Engineering, Data Type, Generalization, Large Data Handling, Computational Complexity, and Interpretability.",
      "Classical Statistics focuses on causal relationships and interpretability with few parameters and structured data. Traditional ML focuses on predictive performance with more parameters and structured/some unstructured data. Deep Learning focuses on optimal prediction on complex, large-scale, multimodal data with millions-trillions of parameters and minimal feature engineering.",
      "The current trend (2025-2026) is to combine Classical Statistics, Traditional ML, and Deep Learning for different stages of a project.",
      "Transformer models overcome RNN/LSTM/GRU limitations (vanishing/exploding gradient, sequential processing, long-range dependencies, fixed-size context) through Self-Attention, parallel processing, Positional Encoding, Feed-Forward layers, Layer Normalization, and Residual connections.",
      "Transformer's ability to scale well with parameters and data led to the discovery of 'scaling law'.",
      "Scaling Law (2020-2025) states that increasing parameters (N), training data (D), and computation (C) exponentially improves model performance along a power-law curve.",
      "Scaling Law's importance: predictable performance, cost-effective improvement (data + compute), explains large investments, and leads to 'emergent abilities'.",
      "Post-training techniques (2025-2026) are crucial for aligning pre-trained LLMs with human values (useful, safe, non-toxic), often involving Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL) based alignment.",
      "RLHF (Reinforcement Learning from Human Feedback) uses human preference data to train a Reward Model (RM), then PPO optimizes the policy to maximize RM reward. It offers strong alignment but is expensive and slow.",
      "PPO (Proximal Policy Optimization) is an RL algorithm used in RLHF, known for stability but still compute-intensive.",
      "DPO (Direct Preference Optimization) directly optimizes policy from preference data (chosen vs rejected pairs) without an explicit RM, offering simplicity, stability, and compute efficiency.",
      "ORPO (Odds Ratio Preference Optimization) combines SFT with preference optimization in a single loss, improving alignment and reducing hallucination.",
      "KTO (Kahneman-Tversky Optimization) uses binary desirable/undesirable labels, making data collection easier.",
      "Newer post-training techniques include SPIN, RLAIF, Constitutional AI, Self-Reward, and Rejection Sampling.",
      "Emergent Abilities are new capabilities that appear suddenly when a model reaches a certain scale (parameters, data, compute), rather than improving gradually (e.g., few-shot learning, Chain-of-Thought reasoning, instruction following).",
      "Emergent abilities are linked to the threshold effect from scaling law, grokked behaviors, compositionality of skills, and diversity in data.",
      "Chain-of-Thought (CoT) Prompting is a technique to improve LLM reasoning by eliciting intermediate reasoning steps (e.g., by adding 'Let's think step by step').",
      "CoT prompting significantly boosts performance in large models on complex reasoning tasks, suggesting it elicits latent 'internal reasoning' from pre-training.",
      "Multimodal Learning involves models processing and integrating multiple data types (text, image, video, audio, sensor data) within a single framework.",
      "Key components of multimodal learning include separate encoders for each modality, fusion mechanisms (early, late, cross-modal attention), and multimodal pre-training objectives (contrastive, generative, masked modeling).",
      "Popular Multimodal Models (2025-2026): CLIP, DALLÂ·E, Stable Diffusion, Flamingo, BLIP/BLIP-2, Kosmos, GPT-4V/GPT-4o, Gemini, Claude 3, LLaVA/MiniGPT-4, VideoPoet, Sora, AudioGPT, MusicGen, PaLM-E.",
      "Applications of these technologies in Vietnam (2025-2026) include medical AI (VinBigData/VinAI), chatbots/voicebots (FPT AI, Zalo AI), speech recognition/synthesis (Viettel AI, VNG/Vbee), e-commerce recommendations, fintech fraud detection, smart cities (VinAI), and education (FPT)."
    ],
    "decisions": [
      "User decided to first understand the difference between Deep Learning, Traditional Machine Learning, and Classical Statistics.",
      "User decided to then understand why Transformer is stronger than RNN/LSTM.",
      "User decided to then understand Scaling Law.",
      "User decided to then understand post-training techniques (RLHF, DPO, ORPO, PPO).",
      "User decided to then understand emergent abilities.",
      "User decided to then understand Chain-of-Thought prompting.",
      "User decided to then understand multimodal learning."
    ],
    "open_questions": [
      "Báº¡n muá»‘n Ä‘i sÃ¢u vÃ o cÃ¡ch implement má»™t VLM Ä‘Æ¡n giáº£n vá»›i HuggingFace, hay tháº£o luáº­n vá» AI alignment trong multimodal?"
    ],
    "todos": []
  },
  "message_range_summarized": {
    "from": 0,
    "to": 15
  }
}

```

**Flow 2 - Ambiguous Query**

Input:

```
TÃ´i dawng awn com
```

Output: 

```
==============================
â“ FLOW 2 â€” AMBIGUOUS QUERY DEMO
==============================
Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
User query: TÃ´i dawng awn com

ğŸ§  Analysis:
{
  "original_query": "TÃ´i dawng awn com",
  "is_ambiguous": true,
  "rewritten_query": "TÃ´i Ä‘ang Äƒn cÆ¡m",
  "needed_context_from_memory": [
    "recent_topic",
    "open_questions",
    "conversation_state",
    "user_preferences"
  ],
  "clarifying_questions": [
    "Báº¡n cÃ³ pháº£i Ä‘ang muá»‘n nÃ³i 'TÃ´i Ä‘ang Äƒn cÆ¡m' khÃ´ng?",
    "Báº¡n cÃ³ muá»‘n tiáº¿p tá»¥c tháº£o luáº­n vá» cÃ¡c chá»§ Ä‘á» AI trÆ°á»›c Ä‘Ã³ khÃ´ng, hay báº¡n Ä‘ang muá»‘n chuyá»ƒn sang má»™t chá»§ Ä‘á» khÃ¡c?"
  ],
  "final_augmented_context": "The user query contains heavy typos, likely meaning 'TÃ´i Ä‘ang Äƒn cÆ¡m' (I am eating). This personal statement, combined with the lack of relation to the `recent_topic` (multimodal learning) and `open_questions` (VLM implementation vs. AI alignment), suggests the user might be making a personal comment or signaling a pause in the conversation, rather than asking a technical question related to the `conversation_state` or `user_preferences`."
}

ğŸ’¬ Assistant response:
Báº¡n cÃ³ pháº£i Ä‘ang muá»‘n nÃ³i 'TÃ´i Ä‘ang Äƒn cÆ¡m' khÃ´ng?
```

## 7. Test Real Time trÃªn Chat Assistant

```
python main.py
```
